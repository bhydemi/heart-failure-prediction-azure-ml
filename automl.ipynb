{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction using AutoML\n",
    "\n",
    "This notebook demonstrates how to use Azure AutoML to train a classification model\n",
    "for predicting heart failure mortality based on clinical records.\n",
    "\n",
    "## Overview\n",
    "1. Setup workspace and compute\n",
    "2. Load and register the dataset\n",
    "3. Configure and run AutoML experiment\n",
    "4. Analyze results and retrieve best model\n",
    "5. Register and deploy the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the workspace\n",
    "ws = Workspace.from_config()\n",
    "print(f\"Workspace name: {ws.name}\")\n",
    "print(f\"Subscription ID: {ws.subscription_id}\")\n",
    "print(f\"Resource group: {ws.resource_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the compute cluster name\n",
    "compute_name = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check if the compute target already exists\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "    print(f\"Found existing compute target: {compute_name}\")\n",
    "except ComputeTargetException:\n",
    "    # Create a new compute cluster\n",
    "    print(f\"Creating new compute cluster: {compute_name}\")\n",
    "    \n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D2_V2\",\n",
    "        max_nodes=4,\n",
    "        min_nodes=0\n",
    "    )\n",
    "    \n",
    "    compute_target = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "print(f\"Compute target status: {compute_target.get_status().serialize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the local dataset\n",
    "df = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(df['DEATH_EVENT'].value_counts())\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# Upload the dataset to the datastore\n",
    "datastore.upload_files(\n",
    "    files=['heart_failure_clinical_records_dataset.csv'],\n",
    "    target_path='heart-failure-data/',\n",
    "    overwrite=True,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Create a TabularDataset from the uploaded file\n",
    "dataset = Dataset.Tabular.from_delimited_files(\n",
    "    path=(datastore, 'heart-failure-data/heart_failure_clinical_records_dataset.csv')\n",
    ")\n",
    "\n",
    "# Register the dataset\n",
    "dataset = dataset.register(\n",
    "    workspace=ws,\n",
    "    name='heart-failure-dataset',\n",
    "    description='Heart Failure Clinical Records Dataset from Kaggle',\n",
    "    create_new_version=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset registered: {dataset.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure AutoML Experiment\n",
    "\n",
    "### AutoML Settings Explained:\n",
    "- **experiment_timeout_minutes**: Maximum time (30 mins) for the entire experiment to prevent excessive resource usage\n",
    "- **max_concurrent_iterations**: Run up to 4 iterations in parallel (matching our compute nodes)\n",
    "- **primary_metric**: Using 'accuracy' as our main optimization metric for classification\n",
    "- **n_cross_validations**: 5-fold cross-validation for robust model evaluation\n",
    "- **enable_early_stopping**: Stop poorly performing runs early to save time\n",
    "- **featurization**: 'auto' lets AutoML handle feature engineering automatically\n",
    "- **enable_onnx_compatible_models**: Enable ONNX export for portability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML settings\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"primary_metric\": 'accuracy',\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"enable_onnx_compatible_models\": True\n",
    "}\n",
    "\n",
    "# AutoML configuration\n",
    "automl_config = AutoMLConfig(\n",
    "    task='classification',\n",
    "    compute_target=compute_target,\n",
    "    training_data=dataset,\n",
    "    label_column_name='DEATH_EVENT',\n",
    "    **automl_settings\n",
    ")\n",
    "\n",
    "print(\"AutoML configuration created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run AutoML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the experiment\n",
    "experiment = Experiment(ws, \"heart-failure-automl\")\n",
    "\n",
    "# Submit the AutoML run\n",
    "print(\"Submitting AutoML experiment...\")\n",
    "automl_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the RunDetails widget to monitor progress\n",
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the run to complete\n",
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrieve and Analyze Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best run and model\n",
    "best_run, best_model = automl_run.get_output()\n",
    "\n",
    "# Display best run details\n",
    "print(f\"Best Run ID: {best_run.id}\")\n",
    "print(f\"\\nBest Model Algorithm: {best_run.properties['run_algorithm']}\")\n",
    "print(f\"\\nBest Model Metrics:\")\n",
    "\n",
    "# Get metrics\n",
    "metrics = best_run.get_metrics()\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model's properties\n",
    "print(\"\\nBest Model Properties:\")\n",
    "print(json.dumps(best_run.properties, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (if available)\n",
    "try:\n",
    "    from azureml.train.automl.runtime.automl_explain_utilities import get_feature_importance\n",
    "    feature_importance = get_feature_importance(best_run)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    for feature, importance in feature_importance.items():\n",
    "        print(f\"  {feature}: {importance}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Register the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the best model\n",
    "model_name = 'heart-failure-automl-model'\n",
    "\n",
    "registered_model = best_run.register_model(\n",
    "    model_name=model_name,\n",
    "    model_path='outputs/model.pkl',\n",
    "    description='Heart Failure Prediction Model trained with AutoML',\n",
    "    tags={\n",
    "        'algorithm': best_run.properties['run_algorithm'],\n",
    "        'accuracy': str(metrics.get('accuracy', 'N/A'))\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model registered: {registered_model.name}\")\n",
    "print(f\"Model version: {registered_model.version}\")\n",
    "print(f\"Model ID: {registered_model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best run's environment\n",
    "best_run_env = best_run.get_environment()\n",
    "\n",
    "# Get the scoring script from AutoML\n",
    "script_file_name = 'scoring_file_v_1_0_0.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
    "\n",
    "print(f\"Downloaded scoring script: {script_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure inference\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script=script_file_name,\n",
    "    environment=best_run_env\n",
    ")\n",
    "\n",
    "# Configure the ACI deployment\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1,\n",
    "    memory_gb=1,\n",
    "    auth_enabled=True,\n",
    "    enable_app_insights=True,\n",
    "    description='Heart Failure Prediction Service (AutoML)'\n",
    ")\n",
    "\n",
    "print(\"Deployment configuration created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "service_name = 'heart-failure-automl-service'\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[registered_model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=aci_config,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(f\"\\nService state: {service.state}\")\n",
    "print(f\"Scoring URI: {service.scoring_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Get the scoring URI and keys\n",
    "scoring_uri = service.scoring_uri\n",
    "primary_key, secondary_key = service.get_keys()\n",
    "\n",
    "# Prepare sample data for testing\n",
    "# Using sample values from the dataset\n",
    "sample_data = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"age\": 75,\n",
    "            \"anaemia\": 0,\n",
    "            \"creatinine_phosphokinase\": 582,\n",
    "            \"diabetes\": 0,\n",
    "            \"ejection_fraction\": 20,\n",
    "            \"high_blood_pressure\": 1,\n",
    "            \"platelets\": 265000,\n",
    "            \"serum_creatinine\": 1.9,\n",
    "            \"serum_sodium\": 130,\n",
    "            \"sex\": 1,\n",
    "            \"smoking\": 0,\n",
    "            \"time\": 4\n",
    "        },\n",
    "        {\n",
    "            \"age\": 55,\n",
    "            \"anaemia\": 0,\n",
    "            \"creatinine_phosphokinase\": 7861,\n",
    "            \"diabetes\": 0,\n",
    "            \"ejection_fraction\": 38,\n",
    "            \"high_blood_pressure\": 0,\n",
    "            \"platelets\": 263358.03,\n",
    "            \"serum_creatinine\": 1.1,\n",
    "            \"serum_sodium\": 136,\n",
    "            \"sex\": 1,\n",
    "            \"smoking\": 0,\n",
    "            \"time\": 6\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Set the headers\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {primary_key}'\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(scoring_uri, json=sample_data, headers=headers)\n",
    "\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save ONNX Model (Optional - Standout Suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get the ONNX model if available\n",
    "try:\n",
    "    from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "    \n",
    "    # Get ONNX model\n",
    "    best_run_onnx, onnx_model = automl_run.get_output(return_onnx_model=True)\n",
    "    \n",
    "    # Save ONNX model\n",
    "    onnx_model_path = 'outputs/automl_model.onnx'\n",
    "    with open(onnx_model_path, 'wb') as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    \n",
    "    print(f\"ONNX model saved to: {onnx_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not export ONNX model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the web service (uncomment to run)\n",
    "# service.delete()\n",
    "# print(\"Service deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the compute cluster (uncomment to run)\n",
    "# compute_target.delete()\n",
    "# print(\"Compute cluster deleted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
